# LLM
## Ref
- [通向AGI之路：大型语言模型（LLM）技术精要](https://zhuanlan.zhihu.com/p/597586623)

**Introduction**
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

**Transformer for NLP**
- [Pytorch transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html?highlight=nn+transformer#torch.nn.Transformer)
  - [Word-level Language Modeling using RNN and Transformer](https://github.com/pytorch/examples/tree/main/word_language_model)
  - [LANGUAGE MODELING WITH NN.TRANSFORMER AND TORCHTEXT](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)

- [基于transformers的自然语言处理(NLP)入门](https://datawhalechina.github.io/learn-nlp-with-transformers/#/./%E7%AF%87%E7%AB%A02-Transformer%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86/2.2-%E5%9B%BE%E8%A7%A3transformer?id=%e9%99%84%e5%8a%a0%e8%b5%84%e6%96%99)

**Spiking Neural Network (SNN)**

- [脉冲神经网络 (Spiking Neural Network) 解读 (一)](https://zhuanlan.zhihu.com/p/416187474)

- [SpikingJelly: 训练大规模SNN](https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based/train_large_scale_snn.html#activation-based-model)
