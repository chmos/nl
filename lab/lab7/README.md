# Lab 7 Neural ODE

## Ref
- [DS - Dynamical Systems & Neural ODEs, a good introduction](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/Dynamical_systems/dynamical_systems_neural_odes.html)

- [PyTorch Implementation of Differentiable ODE Solvers](https://github.com/rtqichen/torchdiffeq/tree/master)

- [Matlab: Dynamical System Modeling Using Neural ODE](https://www.mathworks.com/help/deeplearning/ug/dynamical-system-modeling-using-neural-ode.html)

- [中文介绍](https://zhuanlan.zhihu.com/p/554790455)

- [NODE（神经常微分方程）介绍, 可以用来预测和VAE](https://juejin.cn/post/7151320014975401991)

Tools that may be useful to your framewkork:

- [Autograd](https://github.com/HIPS/autograd)

## ODE
Consider a simple ODE $\vec{x}'=A\vec{x}$:

```python
# ODE, x' = Ax
A = [[-2, 1], [-4, 1]]
A = np.array(A)

lam, X = np.linalg.eig(A)
print('lambda =', lam)
print('X =', X)
v1 = X[:,0]
v2 = X[:,1]

print(v1, A@v1, lam[0] * v1)
print(v2, A@v2, lam[1] * v2)

# v(t) = v1*exp(lambda1 * t) + v2*exp(lambda2 * t)
dt = 0.1
t = np.arange(0, 6, dt)
num = len(t)
T = np.zeros([2, num])
for i in range(num):
    T[:, i] = v1 * np.exp(lam[0]*t[i]) + v2 * np.exp(lam[1]*t[i])

T = np.abs(T)

plt.figure()
plt.plot(T[0, :], T[1, :], '.')
```

## Curve fitting with transformer
This section is generated by ChatGPT, prompt "write a transformer model to fit a curve".

To fit a curve using a transformer model, we will use a neural network based on the transformer architecture. The transformer model was originally designed for natural language processing tasks, but it has also shown promising results in other sequence-to-sequence problems, including curve fitting.

Here's a basic implementation of a transformer model for curve fitting:

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

# Define the transformer model
class TransformerModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads, dropout):
        super(TransformerModel, self).__init__()
        self.embedding = nn.Linear(input_size, hidden_size)
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size, dropout),
            num_layers
        )
        self.output_layer = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.embedding(x)
        x = x.permute(1, 0, 2)  # (seq_len, batch_size, input_size) -> (batch_size, seq_len, input_size)
        x = self.transformer_encoder(x)
        x = x.permute(1, 0, 2)  # (batch_size, seq_len, hidden_size) -> (seq_len, batch_size, hidden_size)
        x = self.output_layer(x)
        return x

# Generate some example data points for a sine wave
num_points = 100
x = np.linspace(0, 2 * np.pi, num_points)
y = np.sin(x)

# Convert data to PyTorch tensors
x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)  # Add a dimension for batch size
y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Add a dimension for batch size

# Create the transformer model
input_size = 1
hidden_size = 32
output_size = 1
num_layers = 2
num_heads = 4
dropout = 0.1
model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads, dropout)

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 1000
for epoch in range(num_epochs):
    optimizer.zero_grad()
    output = model(x)
    loss = criterion(output, y)
    loss.backward()
    optimizer.step()

    if epoch % 100 == 0:
        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')

# Evaluate the model on the training data
with torch.no_grad():
    model.eval()
    predicted_y = model(x)

# Plot the original curve and the fitted curve
plt.plot(x.numpy(), y.numpy(), label='Original')
plt.plot(x.numpy(), predicted_y.numpy(), label='Fitted')
plt.legend()
plt.show()
```

In this example, we create a sine wave curve and use a transformer model to fit the curve. 
The transformer model takes a sequence of x-coordinates as input and predicts the corresponding
y-coordinates. The training loop optimizes the model's parameters to minimize the mean squared 
error loss between the predicted and actual y-coordinates.
